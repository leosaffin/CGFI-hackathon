{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "72d4598d-ca92-4bd7-9c56-f15d19b70ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import iris\n",
    "from iris.analysis import MEAN\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d8f011b-0949-45a0-990b-f85635fa0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "gws = Path(\"/gws/pw/j07/workshop/users/ukcgfi-hackathon/\")\n",
    "\n",
    "depresys = gws / \"data/decadal/depresys/dcppA-hindcast_backup/\"\n",
    "depresys_extra = (\n",
    "    \"s{start_year:04d}-r{ensemble_member:d}i1p1f2/Amon/\"\n",
    "    \"ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_\"\n",
    "    \"s{start_year:04d}-r{ensemble_member:d}i1p1f2_gn_{year:04d}01-{year:04d}12.nc\"\n",
    ")\n",
    "depresys_glob = \"s*-r*i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s*-r*_gn_*01-*12.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38845fb9-c723-4f8b-9061-6a95102d185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted(list(depresys.rglob(depresys_glob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c14599a6-12f7-45ef-a118-2d461721135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/train187/miniforge3/envs/core/lib/python3.13/site-packages/iris/coords.py:2172: IrisVagueMetadataWarning: Cannot check if coordinate is contiguous: Invalid operation for 'realization', with 0 bound(s). Contiguous bounds are only defined for 1D coordinates with 2 bounds. Metadata may not be fully descriptive for 'realization'. Ignoring bounds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# (5N-5S, 170W-120W)\n",
    "enso_region = iris.Constraint(latitude=lambda y: -5 <= y <=5, longitude=lambda x: 190 <= x <= 240)\n",
    "\n",
    "climatology = iris.load_cube(depresys / \"../climatology_files/climatology_1960-2010.nc\")\n",
    "climatology = climatology.collapsed(\"realization\", iris.analysis.MEAN)\n",
    "for coord in [\"latitude\", \"longitude\"]:\n",
    "    climatology.coord(coord).guess_bounds()\n",
    "\n",
    "climatology = climatology.extract(enso_region)\n",
    "weights = iris.analysis.cartography.area_weights(climatology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "642a1a1b-c055-431a-8d49-acb39b5424f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = cubes.concatenate_cube().extract(enso_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e8a5263-90ef-4fe3-a80a-8411df460a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.277771  , -4.72221375, -4.16666412, -3.61110687, -3.05554962,\n",
       "       -2.49999237, -1.94444275, -1.3888855 , -0.83332825, -0.277771  ,\n",
       "        0.27778625,  0.83333588,  1.38889313,  1.94445038,  2.50000763,\n",
       "        3.05555725,  3.6111145 ,  4.16667175,  4.722229  ])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.extract(enso_region).coord(\"latitude\").points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5f7d10a-326d-499d-9820-b3b57b792b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.277771  , -4.7222137 , -4.166664  , -3.6111069 , -3.0555496 ,\n",
       "       -2.4999924 , -1.9444427 , -1.3888855 , -0.83332825, -0.277771  ,\n",
       "        0.27778625,  0.8333359 ,  1.3888931 ,  1.9444504 ,  2.5000076 ,\n",
       "        3.0555573 ,  3.6111145 ,  4.1666718 ,  4.722229  ], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climatology.coord(\"latitude\").points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58a7bab8-3b74-4c82-9bda-ea05458beafe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 18/63 [05:13<13:03, 17.42s/it]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -51] NetCDF: Unknown file format: '/gws/pw/j07/workshop/users/ukcgfi-hackathon/data/decadal/depresys/dcppA-hindcast_backup/s1978-r7i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s1978-r7i1p1f2_gn_198201-198212.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ensemble_member \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m+\u001b[32m1\u001b[39m):\n\u001b[32m      5\u001b[39m     filename = depresys / depresys_extra.format(\n\u001b[32m      6\u001b[39m         start_year=start_year,\n\u001b[32m      7\u001b[39m         ensemble_member=ensemble_member,\n\u001b[32m      8\u001b[39m         year=\u001b[32m9999\u001b[39m,\n\u001b[32m      9\u001b[39m     ).replace(\u001b[33m\"\u001b[39m\u001b[33m999901-999912\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     cubes = \u001b[43miris\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     iris.util.equalise_attributes(cubes)\n\u001b[32m     12\u001b[39m     t = cubes.concatenate_cube().extract(enso_region) - climatology.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:169\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(uris, constraints, callback)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(uris, constraints=\u001b[38;5;28;01mNone\u001b[39;00m, callback=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load any number of Cubes for each constraint.\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m    148\u001b[39m \u001b[33;03m    For a full description of the arguments, please see the module\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m \n\u001b[32m    168\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     cubes = \u001b[43m_load_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m.combined().cubes()\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cubes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:137\u001b[39m, in \u001b[36m_load_collection\u001b[39m\u001b[34m(uris, constraints, callback)\u001b[39m\n\u001b[32m    134\u001b[39m     _MULTIREF_DETECTION.found_multiple_refs = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    136\u001b[39m     cubes = _generate_cubes(uris, callback, constraints)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     result = \u001b[43m_CubeFilterCollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_cubes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcubes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m iris.exceptions.TranslationError(\n\u001b[32m    140\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe file appears empty or incomplete: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    141\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:93\u001b[39m, in \u001b[36m_CubeFilterCollection.from_cubes\u001b[39m\u001b[34m(cubes, constraints)\u001b[39m\n\u001b[32m     91\u001b[39m pairs = [_CubeFilter(constraint) \u001b[38;5;28;01mfor\u001b[39;00m constraint \u001b[38;5;129;01min\u001b[39;00m constraints]\n\u001b[32m     92\u001b[39m collection = _CubeFilterCollection(pairs)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcubes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_cube\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:34\u001b[39m, in \u001b[36m_generate_cubes\u001b[39m\u001b[34m(uris, callback, constraints)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scheme == \u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     33\u001b[39m     part_names = [x[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m groups]\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcube\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miris\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcube\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m scheme \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/io/__init__.py:218\u001b[39m, in \u001b[36mload_files\u001b[39m\u001b[34m(filenames, callback, constraints)\u001b[39m\n\u001b[32m    216\u001b[39m fnames = handler_map[handling_format_spec]\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handling_format_spec.constraint_aware_handler:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcube\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhandling_format_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcube\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/fileformats/netcdf/loader.py:637\u001b[39m, in \u001b[36mload_cubes\u001b[39m\u001b[34m(file_sources, callback, constraints)\u001b[39m\n\u001b[32m    633\u001b[39m     file_sources = [file_sources]\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_source \u001b[38;5;129;01min\u001b[39;00m file_sources:\n\u001b[32m    636\u001b[39m     \u001b[38;5;66;03m# Ingest the file.  At present may be a filepath or an open netCDF4.Dataset.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mCFReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_source\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m cf:\n\u001b[32m    638\u001b[39m         meshes = _meshes_from_cf(cf)\n\u001b[32m    640\u001b[39m         \u001b[38;5;66;03m# Process each CF data variable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/fileformats/cf.py:1310\u001b[39m, in \u001b[36mCFReader.__init__\u001b[39m\u001b[34m(self, file_source, warn, monotonic)\u001b[39m\n\u001b[32m   1307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_source, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1308\u001b[39m     \u001b[38;5;66;03m# Create from filepath : open it + own it (=close when we die).\u001b[39;00m\n\u001b[32m   1309\u001b[39m     \u001b[38;5;28mself\u001b[39m._filename = os.path.expanduser(file_source)\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset = \u001b[43m_thread_safe_nc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDatasetWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28mself\u001b[39m._own_file = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;66;03m# We have been passed an open dataset.\u001b[39;00m\n\u001b[32m   1314\u001b[39m     \u001b[38;5;66;03m# We use it but don't own it (don't close it).\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/fileformats/netcdf/_thread_safe_nc.py:69\u001b[39m, in \u001b[36m_ThreadSafeWrapper.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Create a contained object of the intended type from passed args.\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _GLOBAL_NETCDF4_LOCK:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m         instance = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mCONTAINED_CLASS\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mself\u001b[39m._contained_instance = instance\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2521\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Dataset.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2158\u001b[39m, in \u001b[36mnetCDF4._netCDF4._ensure_nc_success\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: [Errno -51] NetCDF: Unknown file format: '/gws/pw/j07/workshop/users/ukcgfi-hackathon/data/decadal/depresys/dcppA-hindcast_backup/s1978-r7i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s1978-r7i1p1f2_gn_198201-198212.nc'"
     ]
    }
   ],
   "source": [
    "#enso_3p4 = []\n",
    "\n",
    "for start_year in tqdm(range(1960, 2022+1)):\n",
    "    for ensemble_member in range(1, 10+1):\n",
    "        filename = depresys / depresys_extra.format(\n",
    "            start_year=start_year,\n",
    "            ensemble_member=ensemble_member,\n",
    "            year=9999,\n",
    "        ).replace(\"999901-999912\", \"*\")\n",
    "        cubes = iris.load(str(filename))\n",
    "        iris.util.equalise_attributes(cubes)\n",
    "        t = cubes.concatenate_cube().extract(enso_region) - climatology.data\n",
    "        t = t.collapsed([\"latitude\", \"longitude\"], MEAN, weights=weights)\n",
    "        t.add_aux_coord(iris.coords.AuxCoord(start_year, long_name=\"start_year\"))\n",
    "        t.add_aux_coord(iris.coords.AuxCoord(ensemble_member, long_name=\"ensemble_member\"))\n",
    "\n",
    "        enso_3p4.append(t)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6b7b2bb6-3bc8-42ec-a35b-d4c88c6e15bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "One or more of the files specified did not exist:\n    * \"/gws/pw/j07/workshop/users/ukcgfi-hackathon/data/decadal/depresys/dcppA-hindcast_backup/s2019-r1i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s2019-r1i1p1f2_gn_*.nc\" didn't match any files",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ensemble_member \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ensemble_member, \u001b[32m10\u001b[39m+\u001b[32m1\u001b[39m):\n\u001b[32m      3\u001b[39m     filename = depresys / depresys_extra.format(\n\u001b[32m      4\u001b[39m         start_year=start_year,\n\u001b[32m      5\u001b[39m         ensemble_member=ensemble_member,\n\u001b[32m      6\u001b[39m         year=\u001b[32m9999\u001b[39m,\n\u001b[32m      7\u001b[39m     ).replace(\u001b[33m\"\u001b[39m\u001b[33m999901-999912\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     cubes = \u001b[43miris\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     iris.util.equalise_attributes(cubes)\n\u001b[32m     10\u001b[39m     t = cubes.concatenate_cube().extract(enso_region) - climatology.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:169\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(uris, constraints, callback)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(uris, constraints=\u001b[38;5;28;01mNone\u001b[39;00m, callback=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load any number of Cubes for each constraint.\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m    148\u001b[39m \u001b[33;03m    For a full description of the arguments, please see the module\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m \n\u001b[32m    168\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     cubes = \u001b[43m_load_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m.combined().cubes()\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cubes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:137\u001b[39m, in \u001b[36m_load_collection\u001b[39m\u001b[34m(uris, constraints, callback)\u001b[39m\n\u001b[32m    134\u001b[39m     _MULTIREF_DETECTION.found_multiple_refs = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    136\u001b[39m     cubes = _generate_cubes(uris, callback, constraints)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     result = \u001b[43m_CubeFilterCollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_cubes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcubes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m iris.exceptions.TranslationError(\n\u001b[32m    140\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe file appears empty or incomplete: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    141\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:93\u001b[39m, in \u001b[36m_CubeFilterCollection.from_cubes\u001b[39m\u001b[34m(cubes, constraints)\u001b[39m\n\u001b[32m     91\u001b[39m pairs = [_CubeFilter(constraint) \u001b[38;5;28;01mfor\u001b[39;00m constraint \u001b[38;5;129;01min\u001b[39;00m constraints]\n\u001b[32m     92\u001b[39m collection = _CubeFilterCollection(pairs)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcubes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_cube\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:34\u001b[39m, in \u001b[36m_generate_cubes\u001b[39m\u001b[34m(uris, callback, constraints)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scheme == \u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     33\u001b[39m     part_names = [x[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m groups]\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcube\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miris\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcube\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m scheme \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/io/__init__.py:205\u001b[39m, in \u001b[36mload_files\u001b[39m\u001b[34m(filenames, callback, constraints)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a generator of Cubes from given files.\u001b[39;00m\n\u001b[32m    192\u001b[39m \n\u001b[32m    193\u001b[39m \u001b[33;03mTake a list of filenames which may also be globs, and optionally a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m \n\u001b[32m    202\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01miris\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfileformats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FORMAT_AGENT\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m all_file_paths = \u001b[43mexpand_filespecs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Create default dict mapping iris format handler to its associated filenames\u001b[39;00m\n\u001b[32m    208\u001b[39m handler_map = collections.defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/io/__init__.py:183\u001b[39m, in \u001b[36mexpand_filespecs\u001b[39m\u001b[34m(file_specs, files_expected)\u001b[39m\n\u001b[32m    181\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    182\u001b[39m                 msg += \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m    * \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m didn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33mt match any files\u001b[39m\u001b[33m'\u001b[39m.format(pattern)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(msg)\n\u001b[32m    184\u001b[39m     result = [fname \u001b[38;5;28;01mfor\u001b[39;00m fnames \u001b[38;5;129;01min\u001b[39;00m all_expanded \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m fnames]\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mOSError\u001b[39m: One or more of the files specified did not exist:\n    * \"/gws/pw/j07/workshop/users/ukcgfi-hackathon/data/decadal/depresys/dcppA-hindcast_backup/s2019-r1i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s2019-r1i1p1f2_gn_*.nc\" didn't match any files"
     ]
    }
   ],
   "source": [
    "for start_year in tqdm(range(start_year, start_year+1)):\n",
    "    for ensemble_member in range(ensemble_member, 10+1):\n",
    "        filename = depresys / depresys_extra.format(\n",
    "            start_year=start_year,\n",
    "            ensemble_member=ensemble_member,\n",
    "            year=9999,\n",
    "        ).replace(\"999901-999912\", \"*\")\n",
    "        cubes = iris.load(str(filename))\n",
    "        iris.util.equalise_attributes(cubes)\n",
    "        t = cubes.concatenate_cube().extract(enso_region) - climatology.data\n",
    "        t = t.collapsed([\"latitude\", \"longitude\"], MEAN, weights=weights)\n",
    "        t.add_aux_coord(iris.coords.AuxCoord(start_year, long_name=\"start_year\"))\n",
    "        t.add_aux_coord(iris.coords.AuxCoord(ensemble_member, long_name=\"ensemble_member\"))\n",
    "\n",
    "        enso_3p4.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2b6d0e3-1b6f-4ee7-bc2a-625ed9c5c413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 40/43 [08:06<00:36, 12.17s/it]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "One or more of the files specified did not exist:\n    * \"/gws/pw/j07/workshop/users/ukcgfi-hackathon/data/decadal/depresys/dcppA-hindcast_backup/s2019-r1i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s2019-r1i1p1f2_gn_*.nc\" didn't match any files",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ensemble_member \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m+\u001b[32m1\u001b[39m):\n\u001b[32m      3\u001b[39m     filename = depresys / depresys_extra.format(\n\u001b[32m      4\u001b[39m         start_year=start_year,\n\u001b[32m      5\u001b[39m         ensemble_member=ensemble_member,\n\u001b[32m      6\u001b[39m         year=\u001b[32m9999\u001b[39m,\n\u001b[32m      7\u001b[39m     ).replace(\u001b[33m\"\u001b[39m\u001b[33m999901-999912\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     cubes = \u001b[43miris\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     iris.util.equalise_attributes(cubes)\n\u001b[32m     10\u001b[39m     t = cubes.concatenate_cube().extract(enso_region) - climatology.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:169\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(uris, constraints, callback)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(uris, constraints=\u001b[38;5;28;01mNone\u001b[39;00m, callback=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load any number of Cubes for each constraint.\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m    148\u001b[39m \u001b[33;03m    For a full description of the arguments, please see the module\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m \n\u001b[32m    168\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     cubes = \u001b[43m_load_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m.combined().cubes()\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cubes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:137\u001b[39m, in \u001b[36m_load_collection\u001b[39m\u001b[34m(uris, constraints, callback)\u001b[39m\n\u001b[32m    134\u001b[39m     _MULTIREF_DETECTION.found_multiple_refs = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    136\u001b[39m     cubes = _generate_cubes(uris, callback, constraints)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     result = \u001b[43m_CubeFilterCollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_cubes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcubes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m iris.exceptions.TranslationError(\n\u001b[32m    140\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe file appears empty or incomplete: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    141\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:93\u001b[39m, in \u001b[36m_CubeFilterCollection.from_cubes\u001b[39m\u001b[34m(cubes, constraints)\u001b[39m\n\u001b[32m     91\u001b[39m pairs = [_CubeFilter(constraint) \u001b[38;5;28;01mfor\u001b[39;00m constraint \u001b[38;5;129;01min\u001b[39;00m constraints]\n\u001b[32m     92\u001b[39m collection = _CubeFilterCollection(pairs)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcubes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_cube\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/loading.py:34\u001b[39m, in \u001b[36m_generate_cubes\u001b[39m\u001b[34m(uris, callback, constraints)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scheme == \u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     33\u001b[39m     part_names = [x[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m groups]\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcube\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miris\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcube\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m scheme \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/io/__init__.py:205\u001b[39m, in \u001b[36mload_files\u001b[39m\u001b[34m(filenames, callback, constraints)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a generator of Cubes from given files.\u001b[39;00m\n\u001b[32m    192\u001b[39m \n\u001b[32m    193\u001b[39m \u001b[33;03mTake a list of filenames which may also be globs, and optionally a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m \n\u001b[32m    202\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01miris\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfileformats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FORMAT_AGENT\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m all_file_paths = \u001b[43mexpand_filespecs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Create default dict mapping iris format handler to its associated filenames\u001b[39;00m\n\u001b[32m    208\u001b[39m handler_map = collections.defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/io/__init__.py:183\u001b[39m, in \u001b[36mexpand_filespecs\u001b[39m\u001b[34m(file_specs, files_expected)\u001b[39m\n\u001b[32m    181\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    182\u001b[39m                 msg += \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m    * \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m didn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33mt match any files\u001b[39m\u001b[33m'\u001b[39m.format(pattern)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(msg)\n\u001b[32m    184\u001b[39m     result = [fname \u001b[38;5;28;01mfor\u001b[39;00m fnames \u001b[38;5;129;01min\u001b[39;00m all_expanded \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m fnames]\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mOSError\u001b[39m: One or more of the files specified did not exist:\n    * \"/gws/pw/j07/workshop/users/ukcgfi-hackathon/data/decadal/depresys/dcppA-hindcast_backup/s2019-r1i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s2019-r1i1p1f2_gn_*.nc\" didn't match any files"
     ]
    }
   ],
   "source": [
    "for start_year in tqdm(range(start_year+1, 2022)):\n",
    "    for ensemble_member in range(1, 10+1):\n",
    "        filename = depresys / depresys_extra.format(\n",
    "            start_year=start_year,\n",
    "            ensemble_member=ensemble_member,\n",
    "            year=9999,\n",
    "        ).replace(\"999901-999912\", \"*\")\n",
    "        cubes = iris.load(str(filename))\n",
    "        iris.util.equalise_attributes(cubes)\n",
    "        t = cubes.concatenate_cube().extract(enso_region) - climatology.data\n",
    "        t = t.collapsed([\"latitude\", \"longitude\"], MEAN, weights=weights)\n",
    "        t.add_aux_coord(iris.coords.AuxCoord(start_year, long_name=\"start_year\"))\n",
    "        t.add_aux_coord(iris.coords.AuxCoord(ensemble_member, long_name=\"ensemble_member\"))\n",
    "\n",
    "        enso_3p4.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bab3d1d8-5c4c-42ad-bb4b-a9b8f5787889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown / (K)                       (time: 125)\n",
      "    Dimension coordinates:\n",
      "        time                             x\n",
      "    Scalar coordinates:\n",
      "        ensemble_member             1\n",
      "        latitude                    -0.27777099609375 degrees, bound=(-5.555549621582031, 5.000007629394531) degrees\n",
      "        longitude                   215.0 degrees, bound=(189.16666412353516, 240.83333587646484) degrees\n",
      "        start_year                  1960\n",
      "    Cell methods:\n",
      "        0                           latitude: longitude: mean\n",
      "    Attributes:\n",
      "        Conventions                 'CF-1.7 CMIP-6.2'\n",
      "        activity_id                 'DCPP'\n",
      "        branch_method               'no parent'\n",
      "        branch_time_in_child        np.float64(0.0)\n",
      "        branch_time_in_parent       np.float64(0.0)\n",
      "        cmor_version                '3.4.0'\n",
      "        comment                     'Temperature of the lower boundary of the atmosphere'\n",
      "        cv_version                  '6.2.37.5'\n",
      "        data_specs_version          '01.00.29'\n",
      "        experiment                  'hindcast initialized based on observations and using historical forcin ...'\n",
      "        experiment_id               'dcppA-hindcast'\n",
      "        external_variables          'areacella'\n",
      "        forcing_index               np.int32(2)\n",
      "        frequency                   'mon'\n",
      "        further_info_url            'https://furtherinfo.es-doc.org/CMIP6.MOHC.HadGEM3-GC31-MM.dcppA-hindca ...'\n",
      "        grid                        'N216'\n",
      "        grid_label                  'gn'\n",
      "        initialization_index        np.int32(1)\n",
      "        institution                 'Met Office Hadley Centre, Fitzroy Road, Exeter, Devon, EX1 3PB, UK'\n",
      "        institution_id              'MOHC'\n",
      "        license                     'CMIP6 model data produced by Met Office Hadley Centre is licensed under ...'\n",
      "        mip_era                     'CMIP6'\n",
      "        mo_runid                    'u-av640'\n",
      "        nominal_resolution          '100 km'\n",
      "        original_name               'mo: (stash: m01s00i024, lbproc: 128)'\n",
      "        parent_mip_era              'CMIP6'\n",
      "        physics_index               np.int32(1)\n",
      "        product                     'model-output'\n",
      "        realization_index           np.int32(1)\n",
      "        realm                       'atmos'\n",
      "        references                  'Williams, K., et al: The Met Office Global Coupled model 3.0 and 3.1 (GC3.0 ...'\n",
      "        source                      'HadGEM3-GC31-MM (2016): \\naerosol: UKCA-GLOMAP-mode\\natmos: MetUM-HadGEM3-GA7.1 ...'\n",
      "        source_id                   'HadGEM3-GC31-MM'\n",
      "        source_type                 'AOGCM AER'\n",
      "        sub_experiment              'initialized near end of year 1960'\n",
      "        sub_experiment_id           's1960'\n",
      "        table_id                    'Amon'\n",
      "        table_info                  'Creation Date:(13 December 2018) MD5:f0588f7f55b5732b17302f8d9d0d7b8c'\n",
      "        title                       'HadGEM3-GC31-MM output prepared for CMIP6'\n",
      "        variable_id                 'ts'\n",
      "        variable_name               'ts'\n",
      "        variant_label               'r1i1p1f2'\n"
     ]
    }
   ],
   "source": [
    "print(enso_3p4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd82e70a-51e5-4eb0-b990-4076d8843960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 514/590 [35:19<05:13,  4.12s/it]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -51] NetCDF: Unknown file format: '/gws/pw/j07/workshop/users/ukcgfi-hackathon/data/decadal/depresys/dcppA-hindcast_backup/s2011-r5i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s2011-r5i1p1f2_gn_201601-201612.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m         dict_out[\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m] = [t.year]\n\u001b[32m      9\u001b[39m         dict_out[\u001b[33m\"\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m\"\u001b[39m] = [t.month]\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m         dict_out[\u001b[33m\"\u001b[39m\u001b[33mNino3p4\u001b[39m\u001b[33m\"\u001b[39m] = [\u001b[43msubcube\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m[()]]\n\u001b[32m     11\u001b[39m         csv_output.append(dict_out)\n\u001b[32m     13\u001b[39m csv_output = pd.concat(csv_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/cube.py:2853\u001b[39m, in \u001b[36mCube.data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2820\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   2821\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdata\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m   2822\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The :class:`numpy.ndarray` representing the multi-dimensional data of the cube.\u001b[39;00m\n\u001b[32m   2823\u001b[39m \n\u001b[32m   2824\u001b[39m \u001b[33;03m    Notes\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2851\u001b[39m \n\u001b[32m   2852\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2853\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/_data_manager.py:211\u001b[39m, in \u001b[36mDataManager.data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_lazy_data():\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    210\u001b[39m         \u001b[38;5;66;03m# Realise the lazy data.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m         result = \u001b[43mas_concrete_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lazy_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m         \u001b[38;5;66;03m# Assign the realised result.\u001b[39;00m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28mself\u001b[39m._real_array = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/_lazy_data.py:405\u001b[39m, in \u001b[36mas_concrete_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the actual content of a lazy array, as a numpy array.\u001b[39;00m\n\u001b[32m    387\u001b[39m \n\u001b[32m    388\u001b[39m \u001b[33;03mReturn the actual content of a lazy array, as a numpy array.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    402\u001b[39m \n\u001b[32m    403\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_lazy_data(data):\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m     (data,) = \u001b[43m_co_realise_lazy_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/_lazy_data.py:363\u001b[39m, in \u001b[36m_co_realise_lazy_arrays\u001b[39m\u001b[34m(arrays)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_co_realise_lazy_arrays\u001b[39m(arrays):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute multiple lazy arrays and return a list of real values.\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m    All the arrays are computed together, so they can share results for common\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    361\u001b[39m \n\u001b[32m    362\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     computed_arrays = \u001b[43mda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     results = []\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lazy_in, real_out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arrays, computed_arrays):\n\u001b[32m    366\u001b[39m         \u001b[38;5;66;03m# Ensure we always have arrays.\u001b[39;00m\n\u001b[32m    367\u001b[39m         \u001b[38;5;66;03m# Note : in some cases dask (and numpy) will return a scalar\u001b[39;00m\n\u001b[32m    368\u001b[39m         \u001b[38;5;66;03m# numpy.int/numpy.float object rather than an ndarray.\u001b[39;00m\n\u001b[32m    369\u001b[39m         \u001b[38;5;66;03m# Recorded in https://github.com/dask/dask/issues/2111.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/dask/base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/core/lib/python3.13/site-packages/iris/fileformats/netcdf/_thread_safe_nc.py:336\u001b[39m, in \u001b[36mNetCDFDataProxy.__getitem__\u001b[39m\u001b[34m(self, keys)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys):\n\u001b[32m    332\u001b[39m     \u001b[38;5;66;03m# Using a DatasetWrapper causes problems with invalid ID's and the\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# netCDF4 library, presumably because __getitem__ gets called so many\u001b[39;00m\n\u001b[32m    334\u001b[39m     \u001b[38;5;66;03m# times by Dask. Use _GLOBAL_NETCDF4_LOCK directly instead.\u001b[39;00m\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _GLOBAL_NETCDF4_LOCK:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m         dataset = \u001b[43mnetCDF4\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    338\u001b[39m             variable = dataset.variables[\u001b[38;5;28mself\u001b[39m.variable_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2521\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Dataset.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2158\u001b[39m, in \u001b[36mnetCDF4._netCDF4._ensure_nc_success\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: [Errno -51] NetCDF: Unknown file format: '/gws/pw/j07/workshop/users/ukcgfi-hackathon/data/decadal/depresys/dcppA-hindcast_backup/s2011-r5i1p1f2/Amon/ts_Amon_HadGEM3-GC31-MM_dcppA-hindcast_s2011-r5i1p1f2_gn_201601-201612.nc'"
     ]
    }
   ],
   "source": [
    "csv_output = []\n",
    "for cube in tqdm(enso_3p4):\n",
    "    for subcube in cube.slices_over(\"time\"):\n",
    "        t = subcube.coord(\"time\")\n",
    "        t = t.units.num2date(t.points[0])\n",
    "\n",
    "        dict_out = {coord: [subcube.coord(coord).points[0]] for coord in [\"start_year\", \"ensemble_member\"]}\n",
    "        dict_out[\"year\"] = [t.year]\n",
    "        dict_out[\"month\"] = [t.month]\n",
    "        dict_out[\"Nino3p4\"] = [subcube.data[()]]\n",
    "        csv_output.append(dict_out)\n",
    "\n",
    "csv_output = pd.concat(csv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a544bd88-901c-4953-a1b0-8e7a4e737bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_half = pd.DataFrame(csv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "69a54f32-f731-4b5b-8d28-79974290c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_half[\"start_year\"] = [x[0] for x in csv_half[\"start_year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dc99e33d-9baa-4c8b-9fd2-3dba4dceb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\"Nino3p4\"]:\n",
    "    csv_half[var] = [x[0] for x in csv_half[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c1607b37-0f58-4187-ba20-618269aedf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_half.to_csv(\"../depresys_nino3p4.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgfi",
   "language": "python",
   "name": "cgfi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
